{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Предобработка данных"
      ],
      "metadata": {
        "id": "K0GQ4NoRC0b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PVAt4ws_Xly"
      },
      "outputs": [],
      "source": [
        "## Предобработка данных\n",
        "# что включить из предобработки:\n",
        "# 1. выделение русскоязычной лексики из песен\n",
        "# 2. лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# тетрадка загружалась на Kaggle, тк ввиду большого объёма датасеты хранятся там\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "id": "wN4o-uJX_jPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import pandas_profiling\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "egqnQ4UzLKuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/famous-ru-songs-1985-2023/df_1985_2023_top_titles.csv\", encoding='utf8')"
      ],
      "metadata": {
        "id": "h48-jj-oLjku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puncts = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~—«»…'"
      ],
      "metadata": {
        "id": "kiYHbbLrLPDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выделяем русскоязычные тексты песен в отдельный стобец lyrics_ru"
      ],
      "metadata": {
        "id": "PfT-US4JM9F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#добавляем новый столбец по индексу\n",
        "df.insert(13, 'lyrics_ru', 'NaN')"
      ],
      "metadata": {
        "id": "UbF9D94SLr9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "for song in df['lyrics']:\n",
        "    song = str(song)\n",
        "    ru_lyrics_list = []\n",
        "    not_ru_lyrics_list = []\n",
        "\n",
        "    for word in song.split():\n",
        "        word = word.strip(puncts)\n",
        "        try:\n",
        "            ru_lyrics = re.search(r'(([А-Я|Ё]{0,}\\s*([а-я|ё]+\\s*)*)+)', word).groups()[0]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            if len(ru_lyrics) > 0:\n",
        "                ru_lyrics_list.append(ru_lyrics)\n",
        "            else:\n",
        "                pass\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    df['lyrics_ru'].iloc[n] = \" \".join(ru_lyrics_list)\n",
        "\n",
        "    n += 1"
      ],
      "metadata": {
        "id": "odRRBTllL1-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Названия песен"
      ],
      "metadata": {
        "id": "74L3-BQuNia4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Названия песен изначально были представлены в одной колонке на русском и английском языках, задачей было разбить компоненты по разным ячейкам\n"
      ],
      "metadata": {
        "id": "TFB8w6c3Nlgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "for elem in df_1985_2023['title']:\n",
        "    lang = str()\n",
        "    try:\n",
        "        new_elem = re.sub(r'[^\\w\\s]', ' ', df['title'][n])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        ru_name = re.search(r'(([А-Я|Ё]{0,}\\d*\\s*([а-я|ё]+\\d*\\s*)*)+)', new_elem).groups()[0]\n",
        "        df_1985_2023['ru_title'].iloc[n] = str(ru_name)\n",
        "\n",
        "        lang += 'ru '\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        en_name = re.search(r'(([A-Z]{0,}\\d*\\s*([a-z]+\\d*\\s*)+)+)', new_elem).groups()[0]\n",
        "        df_1985_2023['en_title'].iloc[n] = str(en_name)\n",
        "        lang += 'en '\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    df_1985_2023['title_lang'].iloc[n] = lang\n",
        "\n",
        "    n += 1"
      ],
      "metadata": {
        "id": "Or4MpoeMMD_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизация"
      ],
      "metadata": {
        "id": "EUqxh_tiOWX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymystem3"
      ],
      "metadata": {
        "id": "VZvEKXp7OY_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem"
      ],
      "metadata": {
        "id": "d2TuIIE1Oi3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лемматизация текста"
      ],
      "metadata": {
        "id": "IJcEZFDzOpjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#лемматизируем текст и добавим столбец с длиной песени\n",
        "n = 0\n",
        "\n",
        "for song in df['lyrics_ru']:\n",
        "    song = str(song)\n",
        "    m = Mystem()\n",
        "    lemmas = m.lemmatize(song)\n",
        "\n",
        "    df['lemmas_ru_text'].iloc[n] = \" \".join(lemmas)\n",
        "\n",
        "    n += 1"
      ],
      "metadata": {
        "id": "17FYnJwnOoJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лемматизация названий"
      ],
      "metadata": {
        "id": "BfiLRKItOxQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "k = 0\n",
        "for song in df['ru_title']:\n",
        "    try:\n",
        "        song = str(song)\n",
        "        m = Mystem()\n",
        "        lemmas = m.lemmatize(song)\n",
        "\n",
        "        df['lemmas_ru_title'].iloc[n] = \" \".join(lemmas)\n",
        "\n",
        "        n += 1\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "M9eeTkPMO3tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Стобец tags_title не анализировался в работе, но представлен в датасете"
      ],
      "metadata": {
        "id": "Mf2IAOhQVSZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В него вошли грамматические тэги (pymorphy), свойственные словоформам в названиях"
      ],
      "metadata": {
        "id": "ZB6iXJawVr7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.insert(7, 'tags_title', 'NaN')"
      ],
      "metadata": {
        "id": "xfQYHGx9RMyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "qQ1QZqoqRP4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_ru = pymorphy2.MorphAnalyzer(lang='ru')"
      ],
      "metadata": {
        "id": "RgwOcDv0RUMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "\n",
        "for word in df['ru_title'][n].split():\n",
        "    try:\n",
        "        tags = []\n",
        "\n",
        "        p = morph.parse(word)[0]\n",
        "        tag = p.tag\n",
        "        tags.append(str(tag))\n",
        "\n",
        "        df['tags_title'][n] = ' '.join(tags)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    n+=1"
      ],
      "metadata": {
        "id": "mTTg7m2RRXPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизация с удалением стоп-слов"
      ],
      "metadata": {
        "id": "gZLe88fTVtrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/spil_lemmas/ru_stopwords.txt') as f:\n",
        "    stopwords = f.read().split()"
      ],
      "metadata": {
        "id": "Jo9DSvJTV9oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.insert(19, 'lemmas_ru_text_nostopwords', 'NaN')"
      ],
      "metadata": {
        "id": "H7g7QA15WRPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "k = 0\n",
        "\n",
        "for song in df['lemmas_ru_text'][0:]:\n",
        "    no_stopwords_text = []\n",
        "\n",
        "    try:\n",
        "        if type(df['lemmas_ru_title'][n]) == str:\n",
        "            song_with_title = df['lemmas_ru_title'][n] + ' ' + df['lemmas_ru_text'][n]\n",
        "        else:\n",
        "            song_with_title = str(song)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    for word in song_with_title.split():\n",
        "        if word not in stopwords:\n",
        "            no_stopwords_text.append(word)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    df['lemmas_ru_text_nostopwords'].iloc[n] = \" \".join(no_stopwords_text)\n",
        "\n",
        "\n",
        "    n += 1"
      ],
      "metadata": {
        "id": "K7BrPKBHVycj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Удаление столбцов, не релевантных для работы"
      ],
      "metadata": {
        "id": "JZ-AoGNGShMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('language_cld3', inplace=True, axis=1)\n",
        "df.drop('language_ft', inplace=True, axis=1)\n",
        "df.drop('language_id', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "H7UArVPxQ-ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('df_lemmas_upd.csv', encoding='utf8')"
      ],
      "metadata": {
        "id": "EUFqXrA7O0FO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}